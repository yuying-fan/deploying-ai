{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6711f7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will start with a discussion of APIs, set up our Jupyter notebook, and then conquer the LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe804593",
   "metadata": {},
   "source": [
    "# Application Programming Interfaces\n",
    "\n",
    "An Application Programming Interface (API) is a mechanism that enables two software components to communicate with each other using a set of definitions and protocols. ([AWS](https://aws.amazon.com/what-is/api/))\n",
    "\n",
    "+ An *application* is any software with a distinct function. \n",
    "+ An *interface* can be seen as a contract between two applications that specifies how they will communicate with each other.\n",
    "\n",
    "![](./img/01_api.svg)\n",
    "\n",
    "## Types of APIs\n",
    "\n",
    "There are four ways an API can work:\n",
    "\n",
    "### SOAP APIs\n",
    "\n",
    "+ Simple Object Access Protocol. \n",
    "+ Client and server exchange using XML. \n",
    "+ Popular in the past, but less flexible than more modern alternatives.\n",
    "\n",
    "### RPC APIs\n",
    "\n",
    "+ Remote Procedural Calls.\n",
    "+ Client completes a function (or procedure) on the server. \n",
    "+ The server sends the output back to the client.\n",
    "\n",
    "### Websocket APIs\n",
    "\n",
    "+ Uses JSON objects to pass data.\n",
    "+ Supports two-way communication between client app and server.\n",
    "+ Server can send callback messages to connected clients, making it more efficient than REST API.\n",
    "\n",
    "### REST APIs\n",
    "\n",
    "+ Representational State Transfer.\n",
    "+ Most popular and flexible APIs found today.\n",
    "+ Client sends a request to the server as data.\n",
    "+ Server uses this client input to start internal functions and returns output data to the client.\n",
    "+ Defines a set of functions (e.g., GET, PUT, DELETE) that clients can use to access server data.\n",
    "+ Clients and servers exchange data using HTTP.\n",
    "+ REST APIs are stateless: servers do not save client data between requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f299413",
   "metadata": {},
   "source": [
    "## API Endpoints\n",
    "\n",
    "API endpoints are the final touchpoints in the API communication system. API endpoints can be server URLs, services, and other specific digital locations where information is sent and received between systems.\n",
    "\n",
    "Two critical aspects about API Endpoints are:\n",
    "\n",
    "1. Security: API endpoints make the system vulnerable to attack.\n",
    "2. Performance: API endpoints, particularly high-traffic ones, can cause bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c18359",
   "metadata": {},
   "source": [
    "## OpenAI's API\n",
    "\n",
    "+ The OpenAI API is a helpful starting point for building AI applications.\n",
    "+ The API provides endpoints for various services, for example:\n",
    "\n",
    "    - Responses API: https://api.openai.com/v1/responses\n",
    "    - Conversations API: https://api.openai.com/v1/conversations\n",
    "    - Videos API: https://api.openai.com/v1/videos\n",
    "    - Embeddings API: https://api.openai.com/v1/embeddings\n",
    "    - Eval API: https://api.openai.com/v1/evals\n",
    "\n",
    "+ As well, OpenAI offers [Software Development Kits (SDK)](https://platform.openai.com/docs/libraries#install-an-official-sdk) for their APIs. These SDKs allow us to interact with the API with Python functions instead of forming URLs and using tools like curl. SDKs are available for Python, JavaScript, .NET, Java, and Go.\n",
    "+ The API is not the only interface to OpenAI's models and services, for example, \n",
    "\n",
    "    - Web apps are used to interact with GPT models via a chat client, [ChatGPT](https://chatgpt.com/).\n",
    "    - Developers can create agentic workflows using [Agent Builder](https://platform.openai.com/agent-builder) a no-code/low-code alternative to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079138e",
   "metadata": {},
   "source": [
    "# Authentication\n",
    "\n",
    "+ Authentication is the process of verifying a user's or system's identity.\n",
    "+ Authentication (who you are) is generally paired with authorization (what you can do). \n",
    "+ Authenticating to the OpenAI service is done through an SSH Key, Secret Key, or API Key.\n",
    "+ Details can be found in [OpenAI's API Documentation](https://platform.openai.com/docs/api-reference/introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad26e",
   "metadata": {},
   "source": [
    "## Obtaining and Using API Keys\n",
    "\n",
    "+ You can obtain OpenAI API Keys from [this page](https://platform.openai.com/api-keys).\n",
    "+ Consider the following [Best Practices for API Key Safety](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety):\n",
    "\n",
    "    1. Always use a unique API key for each team member on your account. \n",
    "    2. Never deploy your key in client-side environments like browsers or mobile apps.\n",
    "    3. Never commit your key to your repository.\n",
    "    4. Use Environment Variables in place of your API key.\n",
    "    5. Use a Key Management Service.\n",
    "    6. Monitor your account usage and rotate your keys when needed.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712f76e",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Setup\n",
    "\n",
    "In this section, we discuss a few preliminaries that will be useful throughout our lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe751dbe",
   "metadata": {},
   "source": [
    "## Update System Path\n",
    "\n",
    "Add the folder `./05_src/` to the system path. This allows us to reuse our modules in this notebook. We can also avoid duplication as we build on code we have written before.\n",
    "\n",
    "The next cell imports the sys module and appends a relative path ('../../05_src/') to the system path. This allows Python to locate and import custom modules from that directory in subsequent cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../05_src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e30d88",
   "metadata": {},
   "source": [
    "## Use a Logger\n",
    "\n",
    "- A logger affords observability and retains your logs.\n",
    "- Log formats are customizable, and you can include items like timestamp, module, function, line number, and so on.\n",
    "- Log level is also customizable:\n",
    "\n",
    "    + INFO for regular operations.\n",
    "    + DEBUG for development.\n",
    "    + ERROR and WARNING will be logged.\n",
    "\n",
    "- Useful documents on logging:\n",
    "\n",
    "    - [Python logging library](https://docs.python.org/3/library/logging.html).\n",
    "    - [Real Python: Logging](https://realpython.com/python-logging/).\n",
    "    - [The Hitchhiker's Guide to Python: Logging](https://docs.python-guide.org/writing/logging/).\n",
    "\n",
    "The code cell below imports the `get_logger()` function from the `utils.logger` module. Notice that this module is located in ./05_src/utils/logger.py. We can directly load the module because we added the source folder (05_src) to our system path above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bd2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import get_logger\n",
    "_logs = get_logger(__name__, log_dir='../../06_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da49a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 21:44:46,851, 999434666.py, 1, INFO, This is a log message.\n"
     ]
    }
   ],
   "source": [
    "_logs.info('This is a log message.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0942",
   "metadata": {},
   "source": [
    "## Loading Environment Variables\n",
    "\n",
    "+ Environment variables are stored in the operating system environment and not declared within the application itself.\n",
    "+ They are convenient variables for storing settings such as file locations, directories, operational parameters, and log levels, among others.\n",
    "+ They can also store secrets (API keys, passwords, etc.)\n",
    "\n",
    "### Dotenv and .env\n",
    "\n",
    "We can set environment variables in the terminal window, but we can also use a convenient library called [`python-dotenv`](https://pypi.org/project/python-dotenv/).\n",
    "\n",
    "From a Python module, you can call this functionality as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fc7085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../05_src/.secrets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b07fa",
   "metadata": {},
   "source": [
    "However, from a Jupyter notebook, you would usually use something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76030d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.env\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34caf53c",
   "metadata": {},
   "source": [
    "We can obtain the value of an environment variable using [`os.getenv()`](https://docs.python.org/3/library/os.html#os.getenv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b8d22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFO'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv('LOG_LEVEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ce15f",
   "metadata": {},
   "source": [
    "### About .secrets\n",
    "\n",
    "The .secrets file is similar to .env in that it contains key-value pairs intended to be set as environment variables. However, we segregate certain variables, the secrets, into a special file which is then ignored by .git by adding it to .gitignore.\n",
    "\n",
    "A sample of the expected format of .secrets is .secrets.template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328dd79e",
   "metadata": {},
   "source": [
    "# Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed6301",
   "metadata": {},
   "source": [
    "We will use the [OpenAI Python API library](https://github.com/openai/openai-python?tab=readme-ov-file) as our main tool to communicate with OpenAI's API.\n",
    "\n",
    "The code cell below makes a first call to the Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fecd195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', #using gateway so need base url\n",
    "                api_key='any value', #if api key is in secrets, you can remove this line\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini', #use certain model 40 mini model\n",
    "    input = 'Hello world!' #send message to model\n",
    "    \n",
    ")\n",
    "\n",
    "print(response.output_text) #print out the response from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without DSI's gateway, you would do: client = OpenAI()\n",
    "\n",
    "#note this response above is not the full response, it is just the text output from the model. The full response contains more information such as usage, latency, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed011ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'resp_01104f69c4da8c3900698c201d8cac819696bcddc74168e978',\n",
       " 'created_at': 1770790941.0,\n",
       " 'error': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'response',\n",
       " 'output': [{'id': 'msg_01104f69c4da8c3900698c201e1d948196a6ccdca27bd92356',\n",
       "   'content': [{'annotations': [],\n",
       "     'text': 'Hello! How can I assist you today?',\n",
       "     'type': 'output_text',\n",
       "     'logprobs': []}],\n",
       "   'role': 'assistant',\n",
       "   'status': 'completed',\n",
       "   'type': 'message'}],\n",
       " 'parallel_tool_calls': True,\n",
       " 'temperature': 1.0,\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'top_p': 1.0,\n",
       " 'background': False,\n",
       " 'conversation': None,\n",
       " 'max_output_tokens': None,\n",
       " 'max_tool_calls': None,\n",
       " 'previous_response_id': None,\n",
       " 'prompt': None,\n",
       " 'prompt_cache_key': None,\n",
       " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
       " 'safety_identifier': None,\n",
       " 'service_tier': 'default',\n",
       " 'status': 'completed',\n",
       " 'text': {'format': {'type': 'text'}, 'verbosity': 'medium'},\n",
       " 'top_logprobs': 0,\n",
       " 'truncation': 'disabled',\n",
       " 'usage': {'input_tokens': 10,\n",
       "  'input_tokens_details': {'cached_tokens': 0},\n",
       "  'output_tokens': 10,\n",
       "  'output_tokens_details': {'reasoning_tokens': 0},\n",
       "  'total_tokens': 20},\n",
       " 'user': None,\n",
       " 'billing': {'payer': 'developer'},\n",
       " 'completed_at': 1770790942,\n",
       " 'frequency_penalty': 0.0,\n",
       " 'presence_penalty': 0.0,\n",
       " 'prompt_cache_retention': None,\n",
       " 'store': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump() #This will show you the full response from the model, including usage, latency, etc.\n",
    "#you can also explore it item by item, for example: response.usage, response.latency, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795fb577",
   "metadata": {},
   "source": [
    "There are several things happening in this code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb68e77",
   "metadata": {},
   "source": [
    "1. Load the OpenAI library and instantiate a client object. The client object handles authentication, API calls, request/response handling, and error handling. In particular, it will look for an API key in an environment variable called `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62325d02",
   "metadata": {},
   "source": [
    "Alternatively, use an API Gateway by providing the parameters `base_url` and appropriate headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5219ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05951acf",
   "metadata": {},
   "source": [
    "2. We create an API call and store the result in the variable `response`. Notice that the call specifies the model that we want to use, as well as an input. This is a simple call, the [responses API can handle more complex calls](https://platform.openai.com/docs/api-reference/responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6a3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    input = 'Hello world!',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844795a7",
   "metadata": {},
   "source": [
    "3. Print out `output_text` from the response. The repsonse object will contain an attribute called `output` (a list) that contains content (another list) and the content contains text. Below we show these relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4094417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0].content[0].text)\n",
    "#But if you have more than one item in output or content, would need to iterate\n",
    "#So easier to just use response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfacf829",
   "metadata": {},
   "source": [
    "In the sample code, we used a convenience attribute called `output_text` that includes a concatenation of the text in all content and all output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753cb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f1482",
   "metadata": {},
   "source": [
    "**Note**: From the [documentation](https://platform.openai.com/docs/guides/text?api-mode=responses) we know that,\n",
    "\n",
    "> The output array often has more than one item in it! It can contain tool calls, data about reasoning tokens generated by reasoning models, and other items. It is not safe to assume that the model's text output is present at output[0].content[0].text.\n",
    ">\n",
    "> Some of our official SDKs include an output_text property on model responses for convenience, which aggregates all text outputs from the model into a single string. This may be useful as a shortcut to access text output from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6036d3c",
   "metadata": {},
   "source": [
    "Finally, we show the JSON-serialized version of the response object. The response object offers two methods to obtain JSON and dictionary versions of the repsonse: `repsonse.to_json()` and `response.model_dump()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'resp_0ff9bcbee552b00c00698c217169e081918f574c008981ffcf',\n",
       " 'created_at': 1770791281.0,\n",
       " 'error': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'response',\n",
       " 'output': [{'id': 'msg_0ff9bcbee552b00c00698c2171ef84819191df4637fa6577f1',\n",
       "   'content': [{'annotations': [],\n",
       "     'text': 'Hello! How can I assist you today?',\n",
       "     'type': 'output_text',\n",
       "     'logprobs': []}],\n",
       "   'role': 'assistant',\n",
       "   'status': 'completed',\n",
       "   'type': 'message'}],\n",
       " 'parallel_tool_calls': True,\n",
       " 'temperature': 1.0,\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'top_p': 1.0,\n",
       " 'background': False,\n",
       " 'conversation': None,\n",
       " 'max_output_tokens': None,\n",
       " 'max_tool_calls': None,\n",
       " 'previous_response_id': None,\n",
       " 'prompt': None,\n",
       " 'prompt_cache_key': None,\n",
       " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
       " 'safety_identifier': None,\n",
       " 'service_tier': 'default',\n",
       " 'status': 'completed',\n",
       " 'text': {'format': {'type': 'text'}, 'verbosity': 'medium'},\n",
       " 'top_logprobs': 0,\n",
       " 'truncation': 'disabled',\n",
       " 'usage': {'input_tokens': 10,\n",
       "  'input_tokens_details': {'cached_tokens': 0},\n",
       "  'output_tokens': 10,\n",
       "  'output_tokens_details': {'reasoning_tokens': 0},\n",
       "  'total_tokens': 20},\n",
       " 'user': None,\n",
       " 'billing': {'payer': 'developer'},\n",
       " 'completed_at': 1770791282,\n",
       " 'frequency_penalty': 0.0,\n",
       " 'presence_penalty': 0.0,\n",
       " 'prompt_cache_retention': None,\n",
       " 'store': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()\n",
    "#old version, response.to_dict() is deprecated, use model_dump() instead to get the full response in a dictionary format\n",
    "# if need to store as text, can to to_json() instead, which will convert the response to a JSON text string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795e95f",
   "metadata": {},
   "source": [
    "### About the Response API\n",
    "\n",
    "The implementation above could have been completed with another API, for example, Chat. However,  the [documentation](https://platform.openai.com/docs/api-reference/responses) states that the Responses API is:\n",
    "\n",
    "> OpenAI's most advanced interface for generating model responses. Supports text and image inputs, and text outputs. Create stateful interactions with the model, using the output of previous responses as input. Extend the model's capabilities with built-in tools for file search, web search, computer use, and more. Allow the model access to external systems and data using function calling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
