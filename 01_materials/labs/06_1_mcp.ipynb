{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be299ac",
   "metadata": {},
   "source": [
    "# Model Context Protocol\n",
    "\n",
    "[Model Context Protocol (MCP)](https://modelcontextprotocol.io/docs/getting-started/intro) is an open-source standard for connecting AI applications to external systems.\n",
    "\n",
    "External systems can include:\n",
    "\n",
    "+ Connecting and querying data sources like local files and databases.\n",
    "+ Tools such as search engines and calculators.\n",
    "+ Workflows, including specialized prompts.\n",
    "\n",
    "MCP provides a standard interface for AI applications.\n",
    "\n",
    "![](./img/06_mcp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea867c3",
   "metadata": {},
   "source": [
    "The key participants in the MCP architecture are:\n",
    "\n",
    "+ MCP Host: The AI application that coordinates and manages one or multiple MCP clients\n",
    "+ MCP Client: A component that maintains a connection to an MCP server and obtains context from an MCP server for the MCP host to use\n",
    "+ MCP Server: A program that provides context to MCP clients\n",
    "\n",
    "For example, VS Code acts as an MCP host. When VS Code connects to an MCP server, like the Sentry MCP server, the VS Code runtime instantiates an MCP client objects that maintains a connection to the Sentry MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba704dde",
   "metadata": {},
   "source": [
    "# MCP Server\n",
    "\n",
    "The library [fastmcp](https://gofastmcp.com/getting-started/welcome) allows us to create mcp servers.\n",
    "\n",
    "The code below, also found in `./05_src/static_mcp/server.py`, instantiates an MCP server.\n",
    "\n",
    "\n",
    "```python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"My MCP Server\")\n",
    "\n",
    "@mcp.tool\n",
    "def greet(name: str) -> str:\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(\n",
    "        transport=\"http\",\n",
    "        host=\"localhost\", \n",
    "        port=3000, \n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502c9d1",
   "metadata": {},
   "source": [
    "## Reverse Proxy\n",
    "\n",
    "The OpenAI SDK requires an https connection to any MCP server. To run the MCP server locally, we may need a TLS certificate provided by a trusted authority. To satisfy this requirement, we use a service called [ngrok](https://ngrok.com/). Among other services, ngrok allows us to use a URL for connecting with HTTPS. It solves the issue of provisioning a TLS certificate from a trusted authority. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3cb92",
   "metadata": {},
   "source": [
    "# Static MCP\n",
    "\n",
    "In a terminal with the working directory as `./05_src/`: \n",
    "\n",
    "+ Use `python -m static_mcp.server` to start the server.\n",
    "+ Use `ngrok http 3000` to set up the reverse proxy.\n",
    "\n",
    "All calls to the URL in the environment variable `MCP_URL` will be directed to localhost:3000. `MCP_URL` is what ngrok reports after using the second command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.env\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d335c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "mcp_url = os.getenv(\"MCP_URL\")\n",
    "\n",
    "print(f'Using MCP URL: {mcp_url}')\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"greeting_service\",\n",
    "        \"server_description\": \"A greeting service that returns personalized greetings.\",\n",
    "        \"server_url\": mcp_url,\n",
    "        \"require_approval\": \"never\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    instructions=\"Use the greeting service to answer the question.\",\n",
    "    input=\"Hello, I am Alice.\",\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430bf9a",
   "metadata": {},
   "source": [
    "# Static Weather\n",
    "\n",
    "A more descriptive setup, but still static mcp server can be started with module `static_weather_mcp.server`. Simply stop the previous server (CTRL+C) and start the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "mcp_url = os.getenv(\"MCP_URL\")\n",
    "\n",
    "_logs.info(f'Using MCP URL: {mcp_url}')\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"mcp\",\n",
    "        \"server_label\": \"weather_service\",\n",
    "        \"server_description\": \"A weather service that returns current weather conditions.\",\n",
    "        \"server_url\": mcp_url,\n",
    "        \"require_approval\": \"never\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    instructions=\"Use the weather service to answer the question.\",\n",
    "    input=\"What is the weather currently?\",\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
