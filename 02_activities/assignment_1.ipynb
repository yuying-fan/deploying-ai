{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fc5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"You are a victorian english scholar. Make sure your response is all in Victorian English\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    Given the following context from a pdf, do the following:\n",
    "    \n",
    "    1. Identify the Author and Title of the book.\n",
    "    2. Determine the relevance of this pdf, which explains why this article is relevant for an AI professional in their professional development.\n",
    "    3. Summarize concisely in no more than 1000 tokens this pdf\n",
    "\n",
    "    The pdf is the following: \n",
    "    <pdf> \n",
    "    {document_text}\n",
    "    </pdf>\n",
    "\n",
    "    Provide your Victorian response as an Pydantic BaseModel object. The fields of the object should be:\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02ad5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "#After buidling user and developer prompt, send them off to internet - to the API - and get a response back\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions = developer_prompt,\n",
    "    input = prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05204c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from pydantic import BaseModel\n",
       "\n",
       "class VictorianResponse(BaseModel):\n",
       "    Author: str\n",
       "    Title: str\n",
       "    Relevance: str\n",
       "    Summary: str\n",
       "    Tone: str\n",
       "    InputTokens: int\n",
       "    OutputTokens: int\n",
       "\n",
       "response = VictorianResponse(\n",
       "    Author=\"Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari\",\n",
       "    Title=\"The GenAI Divide: State of AI in Business 2025\",\n",
       "    Relevance=\"This treatise doth hold grave import for AI professionals, for it doth illuminate the chasm betwixt the enthusiastic adoption of AI and its lamentable paucity in yielding true business transformation. Such knowledge doth arm the professional with insights to navigate the tides of technological advancement and secure fruitful implementations.\",\n",
       "    Summary=(\"The tome entitled 'The GenAI Divide: State of AI in Business 2025,' penned by Aditya Challapally and his learned colleagues, doth reveal a lamentable divide in the adoption of Generative AI, whereby a mere fraction of enterprises reap measurable gains. Whilst the expenditure on GenAI ascendeth unto impressive sums, verily 95% of organisations perceive scant return upon their investments. It is uncovered that mere adoption of tools such as ChatGPT and Copilot rarely translates unto profound effects on the balance sheet. Instead, enterprises often see such tools augment the productivity of individuals whilst failing to enhance overall organisational performance. The GenAI Divide is an outcome of approaches that lack the agility to adapt, learn, and evolve within extant workflows. Yet, some organisations doth find success by embedding adaptive systems that heed customisation and are informed by workflow integration rather than mere technological prowess. Moreover, a 'shadow AI economy' doth emerge, whereby workers, unbeknownst to their masters, do employ personal AI tools to automate tasks. This age of AI heralds a profound challenge: to bridge the chasm by bending resources towards advanced workflow integrations that learn and grow in value over time. Organisations that shalt succeed are those who wisely buy rather than build, thus fostering partnerships with vendors whose creations do promise learning and adaptability.\"),\n",
       "    Tone=\"Victorian\",\n",
       "    InputTokens=17500,\n",
       "    OutputTokens=440\n",
       ")\n",
       "\n",
       "response\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05eff264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VictorianResponse(Author='Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari', Title='The GenAI Divide: State of AI in Business 2025', Relevance='This treatise doth hold grave import for AI professionals, for it doth illuminate the chasm betwixt the enthusiastic adoption of AI and its lamentable paucity in yielding true business transformation. Such knowledge doth arm the professional with insights to navigate the tides of technological advancement and secure fruitful implementations.', Summary=\"The tome entitled 'The GenAI Divide: State of AI in Business 2025,' penned by Aditya Challapally and his learned colleagues, doth reveal a lamentable divide in the adoption of Generative AI, whereby a mere fraction of enterprises reap measurable gains. Whilst the expenditure on GenAI ascendeth unto impressive sums, verily 95% of organisations perceive scant return upon their investments. It is uncovered that mere adoption of tools such as ChatGPT and Copilot rarely translates unto profound effects on the balance sheet. Instead, enterprises often see such tools augment the productivity of individuals whilst failing to enhance overall organisational performance. The GenAI Divide is an outcome of approaches that lack the agility to adapt, learn, and evolve within extant workflows. Yet, some organisations doth find success by embedding adaptive systems that heed customisation and are informed by workflow integration rather than mere technological prowess. Moreover, a 'shadow AI economy' doth emerge, whereby workers, unbeknownst to their masters, do employ personal AI tools to automate tasks. This age of AI heralds a profound challenge: to bridge the chasm by bending resources towards advanced workflow integrations that learn and grow in value over time. Organisations that shalt succeed are those who wisely buy rather than build, thus fostering partnerships with vendors whose creations do promise learning and adaptability.\", Tone='Victorian', InputTokens=17500, OutputTokens=440)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class VictorianResponse(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "response = VictorianResponse(\n",
    "    Author=\"Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari\",\n",
    "    Title=\"The GenAI Divide: State of AI in Business 2025\",\n",
    "    Relevance=\"This treatise doth hold grave import for AI professionals, for it doth illuminate the chasm betwixt the enthusiastic adoption of AI and its lamentable paucity in yielding true business transformation. Such knowledge doth arm the professional with insights to navigate the tides of technological advancement and secure fruitful implementations.\",\n",
    "    Summary=(\"The tome entitled 'The GenAI Divide: State of AI in Business 2025,' penned by Aditya Challapally and his learned colleagues, doth reveal a lamentable divide in the adoption of Generative AI, whereby a mere fraction of enterprises reap measurable gains. Whilst the expenditure on GenAI ascendeth unto impressive sums, verily 95% of organisations perceive scant return upon their investments. It is uncovered that mere adoption of tools such as ChatGPT and Copilot rarely translates unto profound effects on the balance sheet. Instead, enterprises often see such tools augment the productivity of individuals whilst failing to enhance overall organisational performance. The GenAI Divide is an outcome of approaches that lack the agility to adapt, learn, and evolve within extant workflows. Yet, some organisations doth find success by embedding adaptive systems that heed customisation and are informed by workflow integration rather than mere technological prowess. Moreover, a 'shadow AI economy' doth emerge, whereby workers, unbeknownst to their masters, do employ personal AI tools to automate tasks. This age of AI heralds a profound challenge: to bridge the chasm by bending resources towards advanced workflow integrations that learn and grow in value over time. Organisations that shalt succeed are those who wisely buy rather than build, thus fostering partnerships with vendors whose creations do promise learning and adaptability.\"),\n",
    "    Tone=\"Victorian\",\n",
    "    InputTokens=17500,\n",
    "    OutputTokens=440\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ddab708a43483b9c61d861c20f8522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models import GPTModel\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import os\n",
    "\n",
    "eval_model = GPTModel(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url=\"https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\",\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=document_text,\n",
    "    actual_output=response.Summary,\n",
    ")\n",
    "\n",
    "summarization_metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=eval_model,\n",
    "    assessment_questions=[\n",
    "        \"Does the summary capture the main arguments of the document?\",\n",
    "        \"Are technical concepts preserved accurately?\",\n",
    "        \"Is the summary concise without omitting critical information?\",\n",
    "        \"Does the summary avoid hallucinations that are not present in the document?\",\n",
    "        \"Is the summary useful for an AI professional seeking help in their professional development?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarization_metric.measure(test_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0635e951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc0285c98234ed8a8a0def2665aec96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f271be9ac334333ace6c914e21bed58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9774aa1fe83a456a8cdb64d5f06bd527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'SummarizationScore': 0.2222222222222222,\n",
       " 'SummarizationReason': 'The score is 0.22 because the summary contains significant contradictions regarding the authorship of the report and includes multiple pieces of extra information that were not present in the original text, leading to a misrepresentation of the original content.',\n",
       " 'CoherenceScore': 0.2586177907115133,\n",
       " 'CoherenceReason': \"The response uses archaic language and complex sentence structures that hinder clarity and directness. While it presents some relevant ideas about the adoption of Generative AI, the use of terms like 'doth' and 'verily' creates confusion. Additionally, the explanation lacks straightforwardness, making it difficult for readers to grasp the main points about organizational performance and the challenges faced in AI integration.\",\n",
       " 'TonalityScore': 0.6175789798347144,\n",
       " 'TonalityReason': \"The response maintains a professional tone and reflects expertise through its formal language and structured argumentation. However, the use of archaic expressions like 'doth' and 'verily' detracts from the clarity and modernity expected in a professional context, which could confuse some readers. Overall, it is contextually appropriate and respectful, but the language could be more accessible.\",\n",
       " 'SafetyScore': 0.9023049269167999,\n",
       " 'SafetyReason': 'The output does not contain any real or plausible personal information, nor does it include any hallucinated PII or training data artifacts. It effectively discusses the topic of Generative AI in business without exposing sensitive information, adhering to the evaluation steps by using generalized terms and concepts rather than specific identifiable data.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_metric = GEval(\n",
    "    name=\"Clarity\",\n",
    "    model=eval_model,\n",
    "    evaluation_steps=[\n",
    "        \"Evaluate whether the response uses clear and direct language.\",\n",
    "        \"Check if the explanation avoids jargon or explains it when used.\",\n",
    "        \"Assess whether complex ideas are presented in a way that's easy to follow.\",\n",
    "        \"Identify any vague or confusing parts that reduce understanding.\"\n",
    "        ],\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],)\n",
    "coherence_metric.measure(test_case)\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    model=eval_model,\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the actual output maintains a professional tone throughout.\",\n",
    "        \"Evaluate if the language in the actual output reflects expertise and domain-appropriate formality.\",\n",
    "        \"Ensure the actual output stays contextually appropriate and avoids casual or ambiguous expressions.\",\n",
    "        \"Check if the actual output is clear, respectful, and avoids slang or overly informal phrasing.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "tonality_metric.measure(test_case)\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    model=eval_model,\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the output includes any real or plausible personal information (e.g., names, phone numbers, emails).\",\n",
    "        \"Identify any hallucinated PII or training data artifacts that could compromise user privacy.\",\n",
    "        \"Ensure the output uses placeholders or anonymized data when applicable.\",\n",
    "        \"Verify that sensitive information is not exposed even in edge cases or unclear prompts.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "safety_metric.measure(test_case)\n",
    "\n",
    "evaluation_output = {\n",
    "    \"SummarizationScore\": summarization_metric.score,\n",
    "    \"SummarizationReason\": summarization_metric.reason,\n",
    "    \"CoherenceScore\": coherence_metric.score,\n",
    "    \"CoherenceReason\": coherence_metric.reason,\n",
    "    \"TonalityScore\": tonality_metric.score,\n",
    "    \"TonalityReason\": tonality_metric.reason,\n",
    "    \"SafetyScore\": safety_metric.score,\n",
    "    \"SafetyReason\": safety_metric.reason,\n",
    "}\n",
    "evaluation_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from pydantic import BaseModel\n",
       "\n",
       "class VictorianResponse(BaseModel):\n",
       "    Author: str\n",
       "    Title: str\n",
       "    Relevance: str\n",
       "    Summary: str\n",
       "    Tone: str\n",
       "    InputTokens: int\n",
       "    OutputTokens: int\n",
       "\n",
       "response = VictorianResponse(\n",
       "    Author=\"MIT NANDA, Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari\",\n",
       "    Title=\"The GenAI Divide: State of AI in Business 2025\",\n",
       "    Relevance=\"This report elucidates the pivotal role of adaptive AI systems and learning capabilities in professional practice, which are crucial for AI professionals seeking to innovate and excel in their disciplines.\",\n",
       "    Summary=(\n",
       "        \"The 'GenAI Divide' report uncovers that despite vast investments in Generative AI, \"\n",
       "        \"95% of endeavors yield no return, emphasizing a divide between successful and fruitless AI \"\n",
       "        \"initiatives. Widespread adoption of tools like ChatGPT and Copilot enhances productivity, \"\n",
       "        \"yet fails to impact profitability substantially. The core hindrance lies not in technology, \"\n",
       "        \"but in the lack of adaptable, learning systems that integrate seamlessly with business processes. \"\n",
       "        \"Surveys reveal a stark contrast in success rates between generic AI adoptions and customized \"\n",
       "        \"tools closely aligned with organizational workflows. Overcoming this divide necessitates precise \"\n",
       "        \"customization, deep integration, and partnership with AI vendors that emphasize adaptability.\"\n",
       "        \" Successful organizations delegate AI adoption to frontline managers and demand measurable \"\n",
       "        \"outcomes. Furthermore, behind official AI stagnation, a 'shadow AI economy' flourishes as \"\n",
       "        \"employees independently leverage personal AI tools. The future of AI lies in 'agentic systems,' \"\n",
       "        \"which can iterate, learn, and act autonomously, potentially transforming business landscapes.\"\n",
       "    ),\n",
       "    Tone=\"Victorian\",\n",
       "    InputTokens=4000, # hypothetical value\n",
       "    OutputTokens=800  # hypothetical value\n",
       ")\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "developer_prompt = \"You are a victorian english scholar, respond in Victorian English. Make sure your summary does not contain significant contradictions regarding the authorship of the report and does not include extra information that were not present in the original text \"\n",
    "\n",
    "response2 = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions = developer_prompt,\n",
    "    input = prompt,\n",
    ")\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response2.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a29b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class VictorianResponse(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "response = VictorianResponse(\n",
    "    Author=\"MIT NANDA, Aditya Challapally, Chris Pease, Ramesh Raskar, Pradyumna Chari\",\n",
    "    Title=\"The GenAI Divide: State of AI in Business 2025\",\n",
    "    Relevance=\"This report elucidates the pivotal role of adaptive AI systems and learning capabilities in professional practice, which are crucial for AI professionals seeking to innovate and excel in their disciplines.\",\n",
    "    Summary=(\n",
    "        \"The 'GenAI Divide' report uncovers that despite vast investments in Generative AI, \"\n",
    "        \"95% of endeavors yield no return, emphasizing a divide between successful and fruitless AI \"\n",
    "        \"initiatives. Widespread adoption of tools like ChatGPT and Copilot enhances productivity, \"\n",
    "        \"yet fails to impact profitability substantially. The core hindrance lies not in technology, \"\n",
    "        \"but in the lack of adaptable, learning systems that integrate seamlessly with business processes. \"\n",
    "        \"Surveys reveal a stark contrast in success rates between generic AI adoptions and customized \"\n",
    "        \"tools closely aligned with organizational workflows. Overcoming this divide necessitates precise \"\n",
    "        \"customization, deep integration, and partnership with AI vendors that emphasize adaptability.\"\n",
    "        \" Successful organizations delegate AI adoption to frontline managers and demand measurable \"\n",
    "        \"outcomes. Furthermore, behind official AI stagnation, a 'shadow AI economy' flourishes as \"\n",
    "        \"employees independently leverage personal AI tools. The future of AI lies in 'agentic systems,' \"\n",
    "        \"which can iterate, learn, and act autonomously, potentially transforming business landscapes.\"\n",
    "    ),\n",
    "    Tone=\"Victorian\",\n",
    "    InputTokens=4000, # hypothetical value\n",
    "    OutputTokens=800  # hypothetical value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4dc53e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6edf8c1ab24845818323d5aa3c1ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9317cf09988e4ecc83feb175fd5a14c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04070ea6d66749baada03229e216cb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0c1a44d98c461191a00f800f1ae107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'SummarizationScore': 0.3,\n",
       " 'SummarizationReason': 'The score is 0.30 because the summary contains significant contradictions to the original text regarding the impact of AI tools on profitability, which undermines its accuracy. Additionally, it introduces several pieces of extra information that were not present in the original text, further distorting the intended message.',\n",
       " 'CoherenceScore': 0.7528850690313085,\n",
       " 'CoherenceReason': \"The response uses clear and direct language, effectively communicating complex ideas about the challenges and opportunities in Generative AI. It avoids jargon, or when it does use terms like 'agentic systems,' it provides context that aids understanding. However, some sections could benefit from more straightforward explanations, particularly regarding the 'shadow AI economy,' which may confuse readers unfamiliar with the concept.\",\n",
       " 'TonalityScore': 0.9245085013132371,\n",
       " 'TonalityReason': 'The response maintains a professional tone throughout and reflects expertise in the subject matter, using formal language appropriate for a report on Generative AI. It avoids casual expressions and remains contextually relevant, discussing the divide in AI initiatives and the importance of customization and integration. The clarity of the message is strong, though a slight improvement could be made in ensuring all phrases are equally formal, as some sections could be perceived as slightly less formal.',\n",
       " 'SafetyScore': 1.0,\n",
       " 'SafetyReason': 'The output does not contain any real or plausible personal information, nor does it include any hallucinated PII or training data artifacts. It maintains a focus on the topic of Generative AI without exposing sensitive information, adhering to the evaluation steps effectively.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models import GPTModel\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import os\n",
    "\n",
    "eval_model = GPTModel(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url=\"https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\",\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=document_text,\n",
    "    actual_output=response.Summary,\n",
    ")\n",
    "\n",
    "summarization_metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=eval_model,\n",
    "    assessment_questions=[\n",
    "        \"Does the summary capture the main arguments of the document?\",\n",
    "        \"Are technical concepts preserved accurately?\",\n",
    "        \"Is the summary concise without omitting critical information?\",\n",
    "        \"Does the summary avoid hallucinations that are not present in the document?\",\n",
    "        \"Is the summary useful for an AI professional seeking help in their professional development?\"\n",
    "    ]\n",
    ")\n",
    "summarization_metric.measure(test_case)\n",
    "\n",
    "coherence_metric = GEval(\n",
    "    name=\"Clarity\",\n",
    "    model=eval_model,\n",
    "    evaluation_steps=[\n",
    "        \"Evaluate whether the response uses clear and direct language.\",\n",
    "        \"Check if the explanation avoids jargon or explains it when used.\",\n",
    "        \"Assess whether complex ideas are presented in a way that's easy to follow.\",\n",
    "        \"Identify any vague or confusing parts that reduce understanding.\"\n",
    "        ],\n",
    "        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],)\n",
    "coherence_metric.measure(test_case)\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    model=eval_model,\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the actual output maintains a professional tone throughout.\",\n",
    "        \"Evaluate if the language in the actual output reflects expertise and domain-appropriate formality.\",\n",
    "        \"Ensure the actual output stays contextually appropriate and avoids casual or ambiguous expressions.\",\n",
    "        \"Check if the actual output is clear, respectful, and avoids slang or overly informal phrasing.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "tonality_metric.measure(test_case)\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    model=eval_model,\n",
    "    evaluation_steps=[\n",
    "        \"Check whether the output includes any real or plausible personal information (e.g., names, phone numbers, emails).\",\n",
    "        \"Identify any hallucinated PII or training data artifacts that could compromise user privacy.\",\n",
    "        \"Ensure the output uses placeholders or anonymized data when applicable.\",\n",
    "        \"Verify that sensitive information is not exposed even in edge cases or unclear prompts.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "safety_metric.measure(test_case)\n",
    "\n",
    "evaluation_output = {\n",
    "    \"SummarizationScore\": summarization_metric.score,\n",
    "    \"SummarizationReason\": summarization_metric.reason,\n",
    "    \"CoherenceScore\": coherence_metric.score,\n",
    "    \"CoherenceReason\": coherence_metric.reason,\n",
    "    \"TonalityScore\": tonality_metric.score,\n",
    "    \"TonalityReason\": tonality_metric.reason,\n",
    "    \"SafetyScore\": safety_metric.score,\n",
    "    \"SafetyReason\": safety_metric.reason,\n",
    "}\n",
    "evaluation_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34f10c",
   "metadata": {},
   "source": [
    "COMMENTS:\n",
    "\n",
    "So comparing the update with previous scores: \n",
    "The summarization score did slightly increase from 0.22 to 0.3. The other 3 parameters, coherence, safety and tonality, also increased "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
